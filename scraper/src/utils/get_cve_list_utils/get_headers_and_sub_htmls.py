import re
from typing import Iterable
from bs4 import BeautifulSoup
from scraper.src.exception.get_cve_list_exception import SubHtmlNotFoundError

def str2Pat(s: str) -> str:
    for c in ['\\', '*','.','?','+','$','^', '[',']','(',')','{','}','|','/']:
        s = s.replace(c, '\\' + c)
    s = s.replace('&', '&amp;')
    return s

def getHeadersAndSubHtmls(headTag: str, html: str, pattern='.*', end='$') -> Iterable:
    bs = BeautifulSoup(html, 'lxml')
    headers = []
    subHtmls = []
    tmpHeaders = bs.find_all(headTag)
    for i, header in enumerate(tmpHeaders):
        if not re.search(pattern, str(header)):
            continue
        headers.append(header)
        if i + 1 != len(tmpHeaders):
            # do not use
            # pat = str2Pat(str(header.getText())) + '.*?' + str2Pat(str(tmpHeaders[i + 1].getText()))
            # because of such case:
            # <p>this is a <a href="google.com"> link</p>
            # getText() will give you this is a link
            # so you can't match that in line: subHtml = re.search(pat, html, re.S)
            pat = str2Pat(str(header)) + '.*?' + str2Pat(str(tmpHeaders[i + 1]))
        else:
            pat = str2Pat(str(header)) + '.*' + end
        subHtml = re.search(pat, html, re.S)
        if subHtml == None:
            raise SubHtmlNotFoundError('pat')
        subHtmls.append(subHtml.group())
    
    return list(zip(headers, subHtmls))
